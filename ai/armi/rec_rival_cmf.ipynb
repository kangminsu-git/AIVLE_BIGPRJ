{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.0.1-cp39-cp39-win_amd64.whl (172.4 MB)\n",
      "     -------------------------------------- 172.4/172.4 MB 5.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cmfrec\n",
      "  Downloading cmfrec-3.5.1.post4.tar.gz (268 kB)\n",
      "     -------------------------------------- 268.3/268.3 kB 4.1 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: pandas>=0.25.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from cmfrec) (1.4.4)\n",
      "Requirement already satisfied: cython in c:\\users\\user\\anaconda3\\lib\\site-packages (from cmfrec) (0.29.32)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from cmfrec) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from cmfrec) (1.9.1)\n",
      "Collecting findblas\n",
      "  Using cached findblas-0.1.21-py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from pandas>=0.25.0->cmfrec) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=0.25.0->cmfrec) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.1->pandas>=0.25.0->cmfrec) (1.16.0)\n",
      "Building wheels for collected packages: cmfrec\n",
      "  Building wheel for cmfrec (pyproject.toml): started\n",
      "  Building wheel for cmfrec (pyproject.toml): still running...\n",
      "  Building wheel for cmfrec (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for cmfrec: filename=cmfrec-3.5.1.post4-cp39-cp39-win_amd64.whl size=973386 sha256=185471e80eed89a098a9237bc7a7e679d90c9470cc43b3d7e59d7d1d18522861\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\fb\\34\\7e\\98161f512b5008289e510c24b61e69b010bdebc26478273200\n",
      "Successfully built cmfrec\n",
      "Installing collected packages: findblas, cmfrec\n",
      "Successfully installed cmfrec-3.5.1.post4 findblas-0.1.21\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cmfrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import dataclass_transform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import pickle\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from cmfrec import CMF, CMF_implicit\n",
    "import bottleneck as bn\n",
    "from preprocess import load_data, preprocess_rival\n",
    "\n",
    "#참고: https://cotak.tistory.com/25\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import json\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerize_for_infer(tp, profile2id, show2id):\n",
    "    uid = tp['handle'].apply(lambda x: profile2id[x])\n",
    "    sid = tp['problems'].apply(lambda x: show2id[x])\n",
    "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_item_attributes(problem, user_problems, show2id):\n",
    "    # 문제별 tag 정리\n",
    "    tags = ['math', 'implementation', 'greedy', 'string', 'data-structures', 'geometry', 'dp', 'graphs']\n",
    "    problems_tag = problem[['problemId','tags']]\n",
    "    problems_tag.problem_id = problems_tag.problemId.astype('str')\n",
    "    problems_tag.tags = problems_tag.tags.apply(lambda x: str(x).split(','))\n",
    "    problems_tag = problems_tag.explode('tags').reset_index(drop=True)\n",
    "    problems_tag = problems_tag[problems_tag.tags.isin(tags)]\n",
    "    problems_tag['values']=1\n",
    "    problems_tag = problems_tag.pivot_table(index=\"problemId\", columns=[\"tags\"], aggfunc=np.sum, values='values', fill_value=0)\n",
    "\n",
    "    # 유저가 푼 문제 태그 고르기\n",
    "    problems_tag.reset_index(inplace=True, drop=False)\n",
    "    solved_unique = user_problems.problems.unique()\n",
    "    solved_problems_tag = problems_tag[problems_tag.problemId.isin(solved_unique)]\n",
    "\n",
    "    # 문제 ID 변환\n",
    "    solved_problems_tag.problemId = solved_problems_tag.problemId.apply(lambda x: show2id[x])\n",
    "\n",
    "    # 문제 ID 변환\n",
    "    solved_problems.problemId = solved_problems.problemId.apply(lambda x: show2id[x])\n",
    "\n",
    "    # 푼 문제 고르기\n",
    "    problem.problemId = problem.problemId.astype('str')\n",
    "    solved_unique = user_problems.problems.unique()\n",
    "    solved_problems = problem[problem.problemId.isin(solved_unique)]\n",
    "\n",
    "    # 두 데이터프레임 합치기\n",
    "    item_attributes = pd.merge(solved_problems, solved_problems_tag, left_on='problemId', right_on='problemId')\n",
    "\n",
    "    # 불필요한 행 제거\n",
    "    item_attributes.drop('id', axis=1, inplace=True)\n",
    "    item_attributes.drop('tags', axis=1, inplace=True)\n",
    "    item_attributes.drop('title', axis=1, inplace=True)\n",
    "    item_attributes.drop('isSolvable', axis=1, inplace=True)\n",
    "\n",
    "    # Minmax scaler를 사용하여 scaling 하기\n",
    "    accepted_user_scaler = MinMaxScaler()\n",
    "    avg_tries_scaler = MinMaxScaler()\n",
    "\n",
    "    item_attributes.acceptedUserCount = accepted_user_scaler.fit_transform(item_attributes.acceptedUserCount.values.reshape(-1, 1))\n",
    "    item_attributes.averageTries = avg_tries_scaler.fit_transform(item_attributes.averageTries.values.reshape(-1, 1))\n",
    "\n",
    "    return item_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_user_attributes(user_problems, profile2id, users):\n",
    "    # 푼 유저 고르기\n",
    "    unique_users = user_problems.handle.unique()\n",
    "    users = users[users.handle.isin(unique_users)]\n",
    "\n",
    "    # 유저 ID 변환\n",
    "    users.handle = users.handle.apply(lambda x: profile2id[x])\n",
    "\n",
    "    # 불필요한 행 지우기\n",
    "    users.drop('id', axis=1, inplace=True)\n",
    "    users.drop('rivalCount', axis=1, inplace=True)\n",
    "    users.drop('reverseRivalCount', axis=1, inplace=True)\n",
    "    users.drop('rating', axis=1, inplace=True)\n",
    "    users.drop('rank', axis=1, inplace=True)\n",
    "    users.drop('maxStreak', axis=1, inplace=True)\n",
    "\n",
    "    # Minmax scaler를 사용하여 scaling 하기\n",
    "    solved_count_scaler = MinMaxScaler()\n",
    "    rating_by_problems_sum_scaler = MinMaxScaler()\n",
    "    rating_by_class_scaler = MinMaxScaler()\n",
    "    rating_by_solved_count_scaler = MinMaxScaler()\n",
    "\n",
    "    users.solvedCount = solved_count_scaler.fit_transform(users.solvedCount.values.reshape(-1, 1))\n",
    "    users.ratingByProblemsSum = rating_by_problems_sum_scaler.fit_transform(users.ratingByProblemsSum.values.reshape(-1, 1))\n",
    "    users.ratingByClass = rating_by_class_scaler.fit_transform(users.ratingByClass.values.reshape(-1, 1))\n",
    "    users.ratingBySolvedCount = rating_by_solved_count_scaler.fit_transform(users.ratingBySolvedCount.values.reshape(-1, 1))\n",
    "\n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lst_rivals(i, df_result):\n",
    "    return df_result['r1'][i]+','+df_result['r2'][i]+','+df_result['r3'][i]+','+df_result['r4'][i]+','+df_result['r5'][i]+','+df_result['r6'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_division(num):\n",
    "    for i in range(2, num+1):\n",
    "        if num % i == 0:\n",
    "            return i\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rival_cmf(db):\n",
    "    problem, solved_problem, users, problems_class = load_data(db)\n",
    "\n",
    "    user_problems = solved_problem[['handle', 'problems']]\n",
    "    user_problems.problems = user_problems.problems.str.split(',')\n",
    "    user_problems = user_problems.explode('problems').reset_index(drop=True)\n",
    "    user_problems = user_problems.dropna(axis=0)\n",
    "    \n",
    "    # change id\n",
    "    ## profile id\n",
    "    user_problems = user_problems[user_problems.problems != '']\n",
    "    unique_uid = user_problems.handle.unique()\n",
    "    profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))\n",
    "    ## item ID\n",
    "    unique_sid = pd.unique(user_problems['problems'])\n",
    "    show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "    with open('/home/recognizer14/airflow/dags/module_models/rec_rival/cmf_prog/unique_sid.txt', 'w') as f:\n",
    "        for sid in unique_sid:\n",
    "            f.write('%s\\n' % sid)\n",
    "    with open('/home/recognizer14/airflow/dags/module_models/rec_rival/cmf_prog/show2id.pkl','wb') as f:\n",
    "        pickle.dump(show2id,f)\n",
    "    with open('/home/recognizer14/airflow/dags/module_models/rec_rival/cmf_prog/profile2id.pkl','wb') as f:\n",
    "        pickle.dump(profile2id,f)\n",
    "    print(\"Done Preprocessing\")\n",
    "\n",
    "    # 데이터 준비 \n",
    "    infer_df = numerize_for_infer(user_problems, profile2id, show2id)\n",
    "    ## ratings data\n",
    "    infer_df.columns = ['UserId', 'ItemId']\n",
    "    infer_df['Rating'] = 1\n",
    "    ## item attributes\n",
    "    df_item_attributes = make_item_attributes(problem, user_problems, show2id)\n",
    "    ## user attirubtes\n",
    "    users = make_user_attributes(user_problems, profile2id, users)\n",
    "\n",
    "    ratings = infer_df.copy() ## item attributes\n",
    "    ratings = ratings[ratings.UserId.isin(users.handle.values)]\n",
    "    ratings.reset_index(drop=True, inplace=True)\n",
    "    df_item_attributes = df_item_attributes.rename(columns={\"problem_id\": \"ItemId\"})\n",
    "    item_sideinfo = df_item_attributes.copy()\n",
    "    item_sideinfo = item_sideinfo.sort_values('ItemId').reset_index(drop=True)\n",
    "    \n",
    "    users = users.rename(columns={\"handle\": \"UserId\"}) ##user attributes\n",
    "    user_side_info = users.copy()\n",
    "    user_side_info = user_side_info.sort_values('UserId').reset_index(drop=True)\n",
    "    print(\"Done making side info\")\n",
    "\n",
    "    # 모델링\n",
    "    model_with_sideinfo = CMF_implicit(k=100, lambda_=1e+1, w_main=0.5, w_user=0.5, w_item=0.25)\n",
    "    model_with_sideinfo.fit(X=ratings, U=user_side_info, I=item_sideinfo)\n",
    "    print(\"Done modeling\")\n",
    "\n",
    "    # 비슷한 유저 추천\n",
    "    tmp_user = np.dot(model_with_sideinfo.A_, model_with_sideinfo.C_.T)\n",
    "    emb_user = tmp_user\n",
    "\n",
    "    #유저간 유사도 구하기\n",
    "    #device= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device = \"cpu\"\n",
    "    print(\"DEVICE: \", device)\n",
    "    df_for_cos= torch.tensor(emb_user, dtype=torch.float16)\n",
    "    print(\"torch로 변환  완료\")\n",
    "    df_for_cos= df_for_cos.to(device)\n",
    "    print(\"matmul 시작\")\n",
    "    dot_result= torch.matmul(df_for_cos, df_for_cos.T)\n",
    "    print(df_for_cos.dtype)\n",
    "    #https://discuss.pytorch.org/t/runtimeerror-lu-cuda-not-implemented-for-half/110389\n",
    "    df_for_cos = df_for_cos.type(torch.float32)\n",
    "    print(df_for_cos.dtype)\n",
    "    print(\"size_result 계산 중 \")\n",
    "    size_result= torch.sqrt(torch.sum(df_for_cos**2,axis=1)) * torch.sqrt(torch.sum(df_for_cos.T**2,axis=0))\n",
    "    dot_result /= (size_result+np.finfo('float16').eps)\n",
    "    del size_result\n",
    "    dot_result= dot_result.cpu().numpy()\n",
    "    \n",
    "    print(\"Start computation\")\n",
    "    divisor = first_division(len(dot_result))\n",
    "    print('갯수:', len(dot_result))\n",
    "    print('divisor:', divisor)\n",
    "    i=0\n",
    "    for batch in np.split(dot_result, divisor, axis=0):\n",
    "        if i==0:\n",
    "            index_result= bn.argpartition(-batch, 6, axis=1)[:, :6]\n",
    "        else:\n",
    "            index_result= np.concatenate((index_result,bn.argpartition(-batch, 6, axis=1)[:, :6]),axis=0) \n",
    "        i+=1\n",
    "    print(\"Done finding similar users\")\n",
    "\n",
    "    target_users= list(users.UserId.values)\n",
    "\n",
    "    df_result = pd.DataFrame(index_result)\n",
    "    df_result.columns = ['r1', 'r2', 'r3', 'r4', 'r5', 'r6']\n",
    "    df_result['target'] = target_users\n",
    "    \n",
    "    id2profile = dict((v,k) for k,v in profile2id.items())\n",
    "    df_result['target'] = df_result['target'].apply(lambda x: id2profile[x])\n",
    "    df_result['r1'] = df_result['r1'].apply(lambda x: id2profile[x])\n",
    "    df_result['r2'] = df_result['r2'].apply(lambda x: id2profile[x])\n",
    "    df_result['r3'] = df_result['r3'].apply(lambda x: id2profile[x])\n",
    "    df_result['r4'] = df_result['r4'].apply(lambda x: id2profile[x])\n",
    "    df_result['r5'] = df_result['r5'].apply(lambda x: id2profile[x])\n",
    "    df_result['r6'] = df_result['r6'].apply(lambda x: id2profile[x])\n",
    "\n",
    "    df_result['rec_rivals'] = [make_lst_rivals(i, df_result) for i in range(len(df_result))]\n",
    "    \n",
    "    output = pd.DataFrame(df_result.target.values, columns=['handle'])\n",
    "    output['rec_rivals'] = df_result.rec_rivals\n",
    "    output.index += 1  #mysql에서 auto increment를 위해 1 추가\n",
    "    output.index.name='id'\n",
    "    output.to_csv('C:\\\\Users\\\\User\\\\aivleschool\\\\BIG\\\\rec_rival_cmf.csv')\n",
    "\n",
    "    return output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
